{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling OSM Map Data - by Christopher Ivanovich\n",
    "Written in partial fulfillment of the Udacity Data Analysis Nanodegree requirements\n",
    "\n",
    "## Area of exploration: Tokyo, using OnStreetMap opensource data obtained as an XML file\n",
    "### Getting Our Feet Wet\n",
    "- Full decompressed file size of the Tokyo XML file is in excess of 4GB, used for extracting user contribution data.\n",
    "- Initial checks on the full data set confirmed that all Node elements contain latitude and longtiude values immediately coercible to the float data type. It makes sense that these values would be among the most error-free, given their centrality in meeting the basic needs of a map.\n",
    "\n",
    "### Interesting finds from the full dataset using Python scripts\n",
    "- The top contributor (out of a total of 5437 unique contributors) to the Tokyo OSM dataset has made a staggering 2,000,012 entries as of the time the dataset was downloaded (April 20, 2017). This is over 20,000 more entries than the 2nd-ranked contributor, and highly indicative of the use of a bot pulling data from other source.\n",
    "- There was a total of 21,269,077 entries created by all 5437 unique users (i.e. high-level entries with XML tags of Node, Way, or Relation).\n",
    "\n",
    "## Problems with Standardization\n",
    "\n",
    "After extracting a set of unique Node Tag keys from the map extraction OSM file, it became quite clear that there has not been much in the way of standarization applied to these data. We see that common problems involve:\n",
    "- **Rendering data as keys**, when that data would be better represented as values (e.g. \"microbrewery\" as a key, rather than as a value mapped to the universal \"amenity\" key; \"unisex\", rather than as a value of a generalized additional information key like the common \"note\" key).\n",
    "    - Other \"weird\" keys seem to be the attempt of the contributor to show that something is present or available at a given establishment, as I have found that the value mapped to these keys is often just \"yes\". This explains why someone would think to write \"microwave\" or \"telephone\" as a key, and pair it with the value \"yes\". These keys would also make more sense as values paired with the \"note\" key.\n",
    "\n",
    "- **A lack of standardization around providing names for locations** \n",
    "  - \"name:\" versus simply \"name\" as a key (lack of standardization). When there is a colon it is usually followed by a two-letter language abbreviation, though sometimes with a longer abbreviation (e.g. szl). \n",
    "  - representative examples as k,v tuples: ('name:jp', u'\\u9ebb\\u5e03\\u30a8\\u30f3\\u30d1\\u30a4\\u30a2\\u30de\\u30f3\\u30b7\\u30e7\\u30f3'), ('name', u'\\u5343\\u4'), ('name', 'Muse'), ('name:en', 'MARY JUNE'). These show us that both English and Japanese-script names have been filed under a general \"name\" key, a \"name:en\" key, or a \"name:jp\" key.\n",
    "  - competing attempts also to define the different ways of rendering a Japanese name for a place, e.g. name:ja_rm, lang:ja_kana, lang:ja_rm, lang:ja_full, alt_name:ja (I would argue that the Japanese name should not be an alternative name in Japan).\n",
    "  - and oddly, 'name:etymology:wikidata', because for some reason someone thought to provide scientific details for a particular tree species, and rather than give the source of those details as separate entries with a key like 'reference', they cobbled together that particular abomination.\n",
    "- **A lack of standardization around \"cuisine\" tag entries:** ('cuisine', u'\\u9903\\u5b50'), ('cuisine', 'vegan'),('cuisine:ja', u'\\u4e32\\u713c'). As before, the presence of unicode characters have been confirmed to be primarily Japanese language entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning some of these keys in preparation for creating an SQL database\n",
    "Based on further inspection of the data using several different custom scripts, I believe sensible cleaning tasks include:\n",
    "  - replacing all instances of \"cuisine:xx\" with \"cuisine\", as extracting a full set of cuisine-bearing key, value pairs has shown that the form \"k=cuisine\", \"v=descriptor\" is the prevailing norm, and assigning \"xx\" to be the value descriptor (coerced to \"japanese\" where \"xx\" is \"ja\").\n",
    "  - replacing all key instances of \"name:xx\" with \"xx\", creating a new tag-type called \"name\" for all \"name\" entries, and confirming that a given name value matches the language it is filed under."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What's in a \"name\"?\n",
    "\n",
    "Upon first building the database, 6096 entries in the ways_tags table had \"name\" as a key, while 9206 had it as a tag type. The code provided in the data.py file in the course is aimed at setting anything before the first appearance of a colon \":\" as a tag type. In these 6096 instances, the conflict seemst to have arisen from the XML where ```<tag k='name' />```, i.e. the key has no colon. Further, the same problem was confirmed to arise in the nodes_tags table. In these (numerous) cases, the shape_element method provided writes \"name\" as a key, and lists the tag type as \"regular\", the default tag type.\n",
    "\n",
    "Clearly, it is strange to have almost half of the entries list \"name\" as a key when the other half lists it as a tag type. Furhter, as noted previously, some tag values for names (like 'szl and 'Latn') fail to meet the [ISO 639](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) standard for abbreviating languages. To remedy two birds with one stone, I make use of the **langdetect** library to identify the languages used in the value fields of the tag elements, with the help of an additional method and a slight rewrite of the data.py shape_element method (see next section for the rewrite code):\n",
    "```python\n",
    "from langdetect import detect\n",
    "def langtype(v):\n",
    "    try:\n",
    "        lang = detect(unicode(v)[0])\n",
    "        return lang\n",
    "    except: \n",
    "    #as there are frequent errors involving \"empty values\", which were often numerical \n",
    "    #strings\n",
    "        return v\n",
    "```\n",
    "It needs to be noted that this library fails on multilingual entries like **\"ハロー Hello\"**. I somewhat get around this by limiting the detect method to only the first character of the unicode string, as most multilingual entries seem to be of this ordered form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"cuisine\" travails\n",
    "\n",
    "Also, as noted previously, we encounter a similar problem in auditing cuisine entries. If \"cuisine\" as a key in the XML has no colon followed by some further information, it gets assigned in the SQL table as a key rather than as a tag type, and \"regular\" becomes the defining tag type. Where a 2-letter abbreviation is provided for the cuisine type, cuisine becomes the tag type, creating a conflict between these two formats (e.g. 'ja', 'some_description', 'cuisine' versus 'cuisine', 'description', 'regular' as field entries in the table). We elect to standardize this by forcing the key type to \"cuisine\" if there is a colon present, and overwriting the \"v\" value to be what comes after the colon (most often it is \"ja\" for Japanese). Below is a sample of changes made to the shape_element function in data.py that accomplish this, and also the the changes that accomplished the task above for names and language values.\n",
    "```python\n",
    "def shape_element(\"a ton of arguments\"):\n",
    "    ...some code...\n",
    "        \n",
    " if element.tag == 'node':\n",
    "    node = element.attrib\n",
    "    node_attribs = {k:v for k, v in node.items() if k in node_attr_fields}\n",
    "\n",
    "    node_tags = element.findall(\"tag\")\n",
    "    for elem in node_tags:\n",
    "     #more code omitted, see full data.py file\n",
    "        if 'name' in k: #to handle the problems with the \"name\" entries\n",
    "            ttype = \"name\"\n",
    "            k = langtype(v) #a call to our new helper method\n",
    "        elif 'cuisine:' in elem['k']: #for our cuisine troubles\n",
    "            v = 'japanese' if elem['k'][colpos+1:] == 'ja' else elem['k'][colpos+1:]\n",
    "            #if we see \"cuisine:ja\", assign value as \"japanese\", otherwise, assign what follows the colon\n",
    "            k = 'cuisine'\n",
    "            ttype = \"regular\"\n",
    "        else:\n",
    "            ttype = default_tag_type if \":\" not in elem['k'] else elem['k'][:colpos]\n",
    "        tags.append({'id':id, 'key':k, 'value':v, 'type':ttype})\n",
    "    return {'node': node_attribs, 'node_tags': tags}\n",
    "        \n",
    " #changes are repeated for the \"way tag\" elements\n",
    "```\n",
    "\n",
    "And this seems to have done the trick. At least as far as names and cuisine:ja entries are concerned..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic dataset info\n",
    "A quick note: Initially I attempted this project with a smaller subset of the data, as instruced, using an extract of about 140 MB. But, figuring \"Hey, why not?\", I took on the added challenge of using the full dataset, which, apart from writing the csv files, hasn't been as processor-consuming as I'd feared. I suspect this speaks to the power of relational databases rather than my coding prowess.\n",
    "\n",
    "### File sizes\n",
    "```\n",
    "tokyo_japan.osm ......... 4.03 GB\n",
    "tokyofull.db .......... 2.28 GB\n",
    "nodes.csv ............. 1.48 GB\n",
    "nodes_tags.csv ........ 65.64 MB\n",
    "ways.csv .............. 164.50 MB\n",
    "ways_tags.csv ......... 290.38 MB\n",
    "ways_nodes.csv ......... 519.62 MB\n",
    "```\n",
    "\n",
    "### Number of nodes\n",
    "```\n",
    "sqlite> SELECT COUNT(*) FROM nodes;\n",
    "18405479\n",
    "```\n",
    "### Number of ways\n",
    "```\n",
    "sqlite> SELECT COUNT(*) FROM ways;\n",
    "2853362\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Querying our _cleaner_ database\n",
    "\n",
    "### Unique Users\n",
    "First, I query the database to obtain the number of unique users. For the added functionality of Python 2.7's string encoding/decoding functions I do this using the sqlite library and run scripts from within the Spyder IDE.\n",
    "\n",
    "```Python\n",
    "query1 = \"\"\"SELECT COUNT(distinct e.user)\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e;\"\"\"\n",
    "```\n",
    "This yields a total of __5437 unique users__ across the nodes and ways tables.\n",
    "\n",
    "### Top 10 contributors\n",
    "To obtain the top 10 contributors, I make use of code taken from the sample SQL project provided in the instructions:\n",
    "```Python\n",
    "query2 = \"\"\"SELECT e.user, COUNT(*) as num\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "GROUP BY e.user\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\"\"\"\n",
    "```\n",
    "the results of which are:\n",
    "```python\n",
    "              0        1\n",
    "0   futurumspes  2000012\n",
    "1       Tom_G3X  1838115\n",
    "2         Ryo-a  1014523\n",
    "3      nyampire   888944\n",
    "4         watao   824279\n",
    "5      u_kubota   745968\n",
    "6   Gravel Crew   667555\n",
    "7      kurauchi   667081\n",
    "8       yoshitk   651999\n",
    "9  u_kubota_imp   410133\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cuisine finds\n",
    "```python\n",
    "query3 = '''\n",
    "SELECT count(*)\n",
    "FROM nodes_tags #and again, ways_tags\n",
    "WHERE key = \"cuisine\";'''\n",
    "```\n",
    "yields 13804 and 653 cuisine entries from the nodes_tags and ways_tags tables. Restricting the search to just entries\n",
    "```sql\n",
    "WHERE key = \"cuisine\" AND value LIKE \"ja%\"``` \n",
    "yields a mere 3360 and 196 restaurants explicitly coded as being Japanese, respectively.\n",
    "\n",
    "#### The top ten restaurant entries:\n",
    "```python\n",
    "              0     1\n",
    "0      japanese  3285\n",
    "1   coffee_shop  1450\n",
    "2       chinese  1223\n",
    "3         sushi   811\n",
    "4        noodle   793\n",
    "5         ramen   723\n",
    "6        burger   718\n",
    "7       italian   616\n",
    "8     beef_bowl   298\n",
    "9  noodle;ramen   270\n",
    "```\n",
    "We see that noodle appears essentially three times in this table--much as I love a big bowl of ramen, I wouldn't insist it deserves separate key-level classification from, say, udon or soba. Furthermore, should the \"Japanese\" key coverage be expanded to include noodle, ramen, and noodle;ramen? Does it make sense to label restaurants by ethnicity first, and then to provide further details in another tag or in a third attribute? \n",
    "\n",
    "Also, I believe these values leave out a fair number of restaurants, as I've seen things like \"beaf-bawl\" and \"barger\" which have a large impact on our ability to classify cuisine values. Further, \"noodle\", \"sushi\", and \"ramen\" should all be classed under \"japanese\", if this dataset is to have greater standardization--so too should sushi and beef_bowl, which thus suggests that six of the top ten entries could be folded into the japanese entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission activity by year\n",
    "```python\n",
    "entries_by_year = {}\n",
    "\n",
    "for year in range(2007,2018):\n",
    "    query4 = '''\n",
    "    SELECT COUNT(timestamp)\n",
    "    FROM nodes\n",
    "    WHERE timestamp LIKE \"{0}%\"\n",
    "    ;'''.format(str(year))\n",
    "\n",
    "    c.execute(query4)\n",
    "    rows = c.fetchall()\n",
    "    entries_by_year[year] = rows[0][0]\n",
    "```\n",
    "yields the following pandas DataFrame results (values begin at 2007):\n",
    "```python\n",
    "2007     4045\n",
    "2008    41986\n",
    "2009    85112\n",
    "2010  2026753\n",
    "2011  1766275\n",
    "2012  2694144\n",
    "2013  2419404\n",
    "2014  2277371\n",
    "2015  2677708\n",
    "2016  3176941\n",
    "2017  1235740\n",
    " ```\n",
    " Repeating the process for the Ways table reveals:\n",
    " ```python\n",
    "2007      16\n",
    "2008    3858\n",
    "2009    9126\n",
    "2010   56325\n",
    "2011  265816\n",
    "2012  357937\n",
    "2013  385704\n",
    "2014  402609\n",
    "2015  428042\n",
    "2016  662876\n",
    "2017  281053\n",
    " ```\n",
    " Submission activity for both data types seem to have had high points in 2016, which surprised me given the growing strength of competing projects, like Maps.me. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Exploration\n",
    "### Top 10 Amenities\n",
    "Using an only slightly modified query with key = \"amenity\", we get some more interesting top 10 results:\n",
    "```python\n",
    "                 0      1\n",
    "0           parking  38832\n",
    "1            school   6333\n",
    "2  place_of_worship   2360\n",
    "3        grave_yard   1527\n",
    "4        restaurant   1242\n",
    "5   bicycle_parking   1188\n",
    "6   public_building    799\n",
    "7      kindergarten    757\n",
    "8           toilets    532\n",
    "9          hospital    528\n",
    "```\n",
    "It is tempting to draw inferences about Japanese culture based on the 3rd and 4th place entries (I'll spare you unnecessary masquerading as an anthropologist; although in my memory, graveyards are frequently located on shrine and temple grounds), but it is also important to note that restaurants come in at 5th place, meaning that not all food entries were filed under some variant of \"cuisine\"--yet another problem for another day.\n",
    "\n",
    "Also, clearly the 10th entry is nonsense (only 532 toilets in all locations represented in the Nodes data in the world's (formerly now?) largest city?). \n",
    "\n",
    "Finally, kindergarten could arguably be lumped in with schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The probable role of \"Power Users\" and Messy Entries\n",
    "\n",
    "Two major areas for improvement of the auditing process with this dataset lie in the proliferation of keys describing the same general category of something under many guises (e.g. ramen, beef bowl, noodle for Japanese cuisine), and in the frequent misspellings of user-generated input of all stripes (e.g. tranportationr, beaf_bawl). \n",
    "\n",
    "A quick look at the input from three of our top contributors, __who I define as \"power users\" with entries greater than 1 million__, suggests that the fault lies not with programmatically generated input (Nodes and Ways data), but with human-entered Tags data. Why? Behold!\n",
    "```sql\n",
    "SELECT n.user, count(*)\n",
    "FROM nodes AS n JOIN nodes_tags AS nt ON n.id = nt.id\n",
    "WHERE n.user = \"futurumspes\" OR n.user = \"Tom_G3X\" OR n.user = \"Ryo-a\"\n",
    "GROUP BY n.user;\n",
    "```\n",
    "```python\n",
    "            0      1\n",
    "0        Ryo-a  21164\n",
    "1      Tom_G3X     32\n",
    "2  futurumspes  97410\n",
    "\n",
    "#repeated for ways_tags\n",
    "            0    1\n",
    "0        Ryo-a  215\n",
    "1  futurumspes  127\n",
    "```\n",
    "\n",
    "In the tags dataests these three power users made far fewer tags contribtions as opposed to Nodes and Ways contributions, indicating that they were responsible primarily for mapping out the basic structure of the data, while leaving the nitty-gritty of restaurant names and such to less technically-inclined users. It is almost inconveiably to me that they made as many contributiosn as they have without scanning map data from elsewhere (Tom_G3X in particular did little tagging) which in turn suggests that the observed errors and poor standards are likely at least partially the fault of hand-entered data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To conclude this lengthy report and exploration of the full Tokyo.osm dataset, it seems not at all surprising that there is a lot of messy data here. The amazing thing to me seems to be that a few power users were able to do a solid job generating the basic infrastructure of the map as part of an opensource project contribution.\n",
    "\n",
    "Though it may be a belabored point, this dataset could really benefit from the tightening of standards for tags' key-value pairs, with perhaps an additional field for more detailed description. The current method seems to consist of adding multiple tags for a single location, which invites a great deal of redundancy and possible confusion, as we've seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "As noted, several bits of code were taken from the Udacity Data Analyst Nanodegree's Data Wrangling course module, and modified to suit the needs of this exploration.\n",
    "\n",
    "This .pdf file is a converted Jupyter notebook, and the conversion was made possible thanks to the fantastic Pandoc and MikTex applications.\n",
    "\n",
    "Custom or modified scripts can be found within this project's [GitHub repository](\"https://github.com/sanada1615/Nanodegree/tree/master/P3-Wrangle%20OSM%20Data\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
